{
  "hash": "c95a3866138cdcc057d9c89c9c72aca4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A Method to find Bilingual Features in SparseAutoencoders\"\ndescription: \"A systematic, data driven process to find Bilingual features inside GemmaScope SparseAutoencoder models.\"\nauthor: \"Diego Andrés Gómez Polo\"\ndate: \"9/20/2024\"\nformat:\n  html:\n    code-fold: true\n    code-summary: \"Show source\"\n    code-copy: true\n    smooth-scroll: true\n# bibliography: ref.bib\n# csl: ieee-with-url.csl\n# title-block-banner: images/banner.png\n# title-block-banner-color: black\ncategories: [\"en\", \"NLP\", \"Mechanistic Interpretability\", \"python\"]\n# image: images/thumbnail.png\ntoc: true\ntoc-location: left-body\ncomments: \n  utterances:\n    repo: diegommezp28/playground\n    label: blog-comments\n    theme: github-dark-orange\n    issue-term: pathname\nwebsite:\n  # open-graph: \n  #   image: images/thumbnail.png\n  twitter-card: true\neditor:\n  render-on-save: true\n# jupyter: python3\n---\n\n::: column-margin\n## Reproducibility and Resources\nTo reproduce all the results, feel free to use this [Colab Notebook](https://colab.research.google.com). But, be aware that in order to run the part of the code that gathers the activations, you will need around 24-25GB of RAM in CPU or close to that VRAM if on GPU. The colab free tier does not provide this amount of resources. You can still run the analysis part of the code with this [dataset](https://huggingface.co/datasets/diegomezp/gemmascope_bilingual_activations). The latter will run on almost any relatively modern computer.\n:::\n\n## Introduction\n\n\n\n\n\n## Hopes for Mechanistic Interpretability\n\n## Quick Background on SparseAutoencoders\n\n### Basic Theory\n\n### JumpRelu SparseAutoencoder\n\n### GemmaScope Models\n\n## Methodology\n\n### Quick Overview of GemmaScope SAEs\n\n### Setup and Code\n\n### Results\n\n\n## Conclusion\n\n## Apendix\n\n### On SAELens and TransformersLens\n\n### Interpretation of Feature Dashboards\n\n::: {#703f6a9b .cell .column-page execution_count=1}\n``` {.python .cell-code code-fold=\"true\"}\nfrom IPython.display import IFrame\n\n# get a random feature from the SAE\nfeature_idx = 2647\n\nhtml_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n\ndef get_dashboard_html(sae_release = \"gpt2-small\", sae_id=\"7-res-jb\", feature_idx=0):\n    return html_template.format(sae_release, sae_id, feature_idx)\n\n# Neuronpedia names are usually different to the ones in HF/SAE_Lens\nneuronpedia_sae, neuronpedia_id = \"gemma-2-2b/20-gemmascope-res-16k\".split(\"/\")\nhtml = get_dashboard_html(sae_release = neuronpedia_sae, sae_id=neuronpedia_id, feature_idx=feature_idx)\nIFrame(html, width=1200, height=600)\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```{=html}\n\n        <iframe\n            width=\"1200\"\n            height=\"600\"\n            src=\"https://neuronpedia.org/gemma-2-2b/20-gemmascope-res-16k/2647?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        \n```\n:::\n:::\n\n\n...\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}